{
  "version": 3,
  "sources": ["src/app/services/gemini-translation.service.ts", "src/app/services/local-ai-translation.service.ts"],
  "sourcesContent": ["import { Injectable } from '@angular/core';\nimport { Observable, throwError, from } from 'rxjs';\nimport { map, catchError } from 'rxjs/operators';\nimport { GoogleGenAI } from '@google/genai';\nimport { CryptoUtil } from '../utils/crypto.util';\nimport * as CryptoJS from 'crypto-js';\n\nexport interface TranslationResult {\n  originalText: string;\n  translatedText: string;\n  targetLanguage: string;\n  success: boolean;\n  error?: string;\n}\n\n@Injectable({\n  providedIn: 'root'\n})\nexport class GeminiTranslationService {\n  private readonly ENCRYPTED_API_KEY = 'U2FsdGVkX19ILCT33NvRMnrfGuGerBksJREzwCDAIb7VpwUoVn/Oc3vrAqfYplC8SjPFUU3npbu+85eFwOKgpw==';\n  private readonly ENCRYPTION_KEY = 'ezReader';\n  private readonly API_KEY: string;\n  private ai: GoogleGenAI;\n\n  constructor() {\n    // 암호화된 키를 복호화\n    try {\n      const decrypted = CryptoJS.AES.decrypt(this.ENCRYPTED_API_KEY, this.ENCRYPTION_KEY);\n      this.API_KEY = decrypted.toString(CryptoJS.enc.Utf8);\n    } catch (error) {\n      console.error('API 키 복호화 실패:', error);\n      this.API_KEY = '';\n    }\n    this.ai = new GoogleGenAI({ apiKey: this.API_KEY });\n    console.log('GeminiTranslationService initialized with gemini-2.5-flash model');\n  }\n\n  /**\n   * 텍스트를 지정된 언어로 번역\n   */\n  translateText(text: string, targetLanguage: string): Observable<TranslationResult> {\n    if (!text.trim()) {\n      return throwError(() => new Error('번역할 텍스트가 없습니다.'));\n    }\n\n    const languageMap = {\n      'english': 'English',\n      'korean': 'Korean',\n      'japanese': 'Japanese',\n      'chinese': 'Chinese',\n      'spanish': 'Spanish',\n      'french': 'French',\n      'german': 'German'\n    };\n\n    const targetLangName = languageMap[targetLanguage as keyof typeof languageMap] || 'English';\n    \n    const prompt = `Translate the following text to ${targetLangName}. Provide only the translation without any explanations or additional text:\n\n${text}`;\n\n    return from(\n      this.ai.models.generateContent({\n        model: 'gemini-2.5-flash',\n        contents: prompt,\n      })\n    ).pipe(\n      map(response => {\n        console.log('Gemini API 번역 응답:', response);\n        \n        if (response && response.text) {\n          const translatedText = response.text.trim();\n          return {\n            originalText: text,\n            translatedText: translatedText,\n            targetLanguage: targetLangName,\n            success: true\n          };\n        } else {\n          throw new Error('번역 응답을 받을 수 없습니다.');\n        }\n      }),\n      catchError(error => {\n        console.error('Gemini API 번역 오류:', error);\n        let errorMessage = '번역 중 오류가 발생했습니다.';\n        if (error.message) {\n          errorMessage = error.message;\n        }\n        \n        return throwError(() => ({\n          originalText: text,\n          translatedText: '',\n          targetLanguage: targetLangName,\n          success: false,\n          error: errorMessage\n        }));\n      })\n    );\n  }\n\n  /**\n   * 여러 텍스트 블록을 순차적으로 번역\n   */\n  translateMultipleTexts(texts: string[], targetLanguage: string): Observable<TranslationResult[]> {\n    const translations: TranslationResult[] = [];\n    \n    return new Observable(observer => {\n      let currentIndex = 0;\n      \n      const translateNext = () => {\n        if (currentIndex >= texts.length) {\n          observer.next(translations);\n          observer.complete();\n          return;\n        }\n\n        const currentText = texts[currentIndex];\n        this.translateText(currentText, targetLanguage).subscribe({\n          next: (result) => {\n            translations.push(result);\n            currentIndex++;\n            // 짧은 지연을 두어 API 제한을 방지\n            setTimeout(translateNext, 100);\n          },\n          error: (error) => {\n            translations.push({\n              originalText: currentText,\n              translatedText: '',\n              targetLanguage: targetLanguage,\n              success: false,\n              error: error.message || '번역 실패'\n            });\n            currentIndex++;\n            setTimeout(translateNext, 100);\n          }\n        });\n      };\n\n      translateNext();\n    });\n  }\n}\n", "import { Injectable } from '@angular/core';\nimport { HttpClient, HttpHeaders } from '@angular/common/http';\nimport { Observable, throwError, from } from 'rxjs';\nimport { map, catchError } from 'rxjs/operators';\n\nexport interface LocalAITranslationResult {\n  originalText: string;\n  translatedText: string;\n  targetLanguage: string;\n  success: boolean;\n  error?: string;\n}\n\nexport interface OllamaResponse {\n  response: string;\n  done: boolean;\n  context?: number[];\n  total_duration?: number;\n  load_duration?: number;\n  prompt_eval_count?: number;\n  prompt_eval_duration?: number;\n  eval_count?: number;\n  eval_duration?: number;\n}\n\nexport interface OllamaModel {\n  name: string;\n  modified_at: string;\n  size: number;\n  digest: string;\n}\n\nexport interface OllamaListResponse {\n  models: OllamaModel[];\n}\n\n@Injectable({\n  providedIn: 'root'\n})\nexport class LocalAiTranslationService {\n  private readonly OLLAMA_BASE_URL = 'http://localhost:11434';\n  private readonly TARGET_MODEL = 'gemma3:1b';\n\n  constructor(private http: HttpClient) {}\n\n  /**\n   * Ollama가 설치되어 있고 gemma2:1b 모델이 사용 가능한지 확인\n   */\n  async checkOllamaAvailability(): Promise<boolean> {\n    // 로컬 Ollama API 호출 비활성화\n    return false;\n    \n    // try {\n    //   \n    //   // 먼저 Ollama 서버가 실행 중인지 확인\n    //   const healthCheck = await this.http.get(`${this.OLLAMA_BASE_URL}/api/tags`, {\n    //     headers: new HttpHeaders({\n    //       'Content-Type': 'application/json'\n    //     })\n    //   }).toPromise() as OllamaListResponse;\n\n\n    //   // gemma3:1b 모델이 있는지 확인\n    //   const hasTargetModel = healthCheck.models.some(model => \n    //     model.name.includes('gemma3:1b') || model.name.includes('gemma3') || model.name.includes('gemma')\n    //   );\n\n    //   console.log('사용 가능한 모델들:', healthCheck.models.map(m => m.name));\n\n    //   return hasTargetModel;\n    // } catch (error) {\n    //   return false;\n    // }\n  }\n\n  /**\n   * 로컬 AI를 사용하여 텍스트 번역\n   */\n  translateText(text: string, targetLanguage: string): Observable<LocalAITranslationResult> {\n    if (!text.trim()) {\n      return throwError(() => new Error('번역할 텍스트가 없습니다.'));\n    }\n\n    const languageMap = {\n      'english': '영어',\n      'korean': '한국어',\n      'japanese': '일본어',\n      'chinese': '중국어',\n      'spanish': '스페인어',\n      'french': '프랑스어',\n      'german': '독일어'\n    };\n\n    const targetLangName = languageMap[targetLanguage as keyof typeof languageMap] || targetLanguage;\n\n    const prompt = `다음 텍스트를 ${targetLangName}로 번역해주세요. 번역된 내용만 응답하고 다른 설명은 포함하지 마세요.\n\n텍스트:\n${text}\n\n번역:`;\n\n    const requestBody = {\n      model: this.TARGET_MODEL,\n      prompt: prompt,\n      stream: false,\n      options: {\n        temperature: 0.3,\n        top_p: 0.9,\n        max_tokens: 4000\n      }\n    };\n\n    const headers = new HttpHeaders({\n      'Content-Type': 'application/json'\n    });\n\n\n    return this.http.post<OllamaResponse>(`${this.OLLAMA_BASE_URL}/api/generate`, requestBody, { headers })\n      .pipe(\n        map((response: OllamaResponse) => {\n          \n          if (response.response && response.response.trim()) {\n            return {\n              originalText: text,\n              translatedText: response.response.trim(),\n              targetLanguage: targetLanguage,\n              success: true\n            };\n          } else {\n            throw new Error('번역 응답이 비어있습니다.');\n          }\n        }),\n        catchError((error) => {\n          let errorMessage = '로컬 AI 번역 중 오류가 발생했습니다.';\n          \n          if (error.status === 0) {\n            errorMessage = 'Ollama 서버에 연결할 수 없습니다. Ollama가 실행 중인지 확인해주세요.';\n          } else if (error.status === 404) {\n            errorMessage = `${this.TARGET_MODEL} 모델을 찾을 수 없습니다. 모델을 설치해주세요.`;\n          } else if (error.error?.error) {\n            errorMessage = error.error.error;\n          } else if (error.message) {\n            errorMessage = error.message;\n          }\n\n          return throwError(() => ({\n            originalText: text,\n            translatedText: '',\n            targetLanguage: targetLanguage,\n            success: false,\n            error: errorMessage\n          }));\n        })\n      );\n  }\n\n  /**\n   * 로컬 AI를 사용하여 텍스트 요약\n   */\n  summarizeText(text: string, summaryType: string = 'general', summaryLength: string = 'medium'): Observable<LocalAITranslationResult> {\n    if (!text.trim()) {\n      return throwError(() => new Error('요약할 텍스트가 없습니다.'));\n    }\n\n    let prompt = '';\n    \n    // 요약 유형에 따른 프롬프트 생성\n    switch (summaryType) {\n      case 'bullet':\n        prompt = `다음 문서의 핵심 포인트를 번호가 매겨진 목록으로 요약해주세요. `;\n        break;\n      case 'qa':\n        prompt = `다음 문서를 Q&A 형식으로 요약해주세요. 주요 질문과 답변으로 구성해주세요. `;\n        break;\n      case 'structure':\n        prompt = `다음 문서를 구조적으로 요약해주세요. 제목, 주요 섹션, 핵심 내용을 체계적으로 정리해주세요. `;\n        break;\n      default:\n        prompt = `다음 문서를 요약해주세요. `;\n    }\n    \n    // 요약 길이에 따른 지시사항 추가\n    switch (summaryLength) {\n      case 'short':\n        prompt += `간결하게 1-2문단으로 요약해주세요. `;\n        break;\n      case 'long':\n        prompt += `자세하게 5-6문단으로 요약해주세요. `;\n        break;\n      default:\n        prompt += `적절한 길이로 3-4문단으로 요약해주세요. `;\n    }\n    \n    prompt += `한국어로 작성해주세요. 요약된 내용만 응답하고 다른 설명은 포함하지 마세요.\\n\\n문서 내용:\\n${text}`;\n\n    const requestBody = {\n      model: this.TARGET_MODEL,\n      prompt: prompt,\n      stream: false,\n      options: {\n        temperature: 0.3,\n        top_p: 0.9,\n        max_tokens: 4000\n      }\n    };\n\n    const headers = new HttpHeaders({\n      'Content-Type': 'application/json'\n    });\n\n\n    return this.http.post<OllamaResponse>(`${this.OLLAMA_BASE_URL}/api/generate`, requestBody, { headers })\n      .pipe(\n        map((response: OllamaResponse) => {\n          \n          if (response.response && response.response.trim()) {\n            return {\n              originalText: text,\n              translatedText: response.response.trim(),\n              targetLanguage: 'korean',\n              success: true\n            };\n          } else {\n            throw new Error('요약 응답이 비어있습니다.');\n          }\n        }),\n        catchError((error) => {\n          let errorMessage = '로컬 AI 요약 중 오류가 발생했습니다.';\n          \n          if (error.status === 0) {\n            errorMessage = 'Ollama 서버에 연결할 수 없습니다. Ollama가 실행 중인지 확인해주세요.';\n          } else if (error.status === 404) {\n            errorMessage = `${this.TARGET_MODEL} 모델을 찾을 수 없습니다. 모델을 설치해주세요.`;\n          } else if (error.error?.error) {\n            errorMessage = error.error.error;\n          } else if (error.message) {\n            errorMessage = error.message;\n          }\n\n          return throwError(() => ({\n            originalText: text,\n            translatedText: '',\n            targetLanguage: 'korean',\n            success: false,\n            error: errorMessage\n          }));\n        })\n      );\n  }\n  async getAvailableModels(): Promise<string[]> {\n    // 로컬 Ollama API 호출 비활성화\n    return [];\n    \n    // try {\n    //   const response = await this.http.get<OllamaListResponse>(`${this.OLLAMA_BASE_URL}/api/tags`).toPromise();\n    //   return response?.models.map(model => model.name) || [];\n    // } catch (error) {\n    //   return [];\n    // }\n  }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;AAKA,eAA0B;AAapB,IAAO,2BAAP,MAAO,0BAAwB;EAClB,oBAAoB;EACpB,iBAAiB;EACjB;EACT;EAER,cAAA;AAEE,QAAI;AACF,YAAM,YAAqB,aAAI,QAAQ,KAAK,mBAAmB,KAAK,cAAc;AAClF,WAAK,UAAU,UAAU,SAAkB,aAAI,IAAI;IACrD,SAAS,OAAO;AACd,cAAQ,MAAM,+CAAiB,KAAK;AACpC,WAAK,UAAU;IACjB;AACA,SAAK,KAAK,IAAI,YAAY,EAAE,QAAQ,KAAK,QAAO,CAAE;AAClD,YAAQ,IAAI,kEAAkE;EAChF;;;;EAKA,cAAc,MAAc,gBAAsB;AAChD,QAAI,CAAC,KAAK,KAAI,GAAI;AAChB,aAAO,WAAW,MAAM,IAAI,MAAM,uEAAgB,CAAC;IACrD;AAEA,UAAM,cAAc;MAClB,WAAW;MACX,UAAU;MACV,YAAY;MACZ,WAAW;MACX,WAAW;MACX,UAAU;MACV,UAAU;;AAGZ,UAAM,iBAAiB,YAAY,cAA0C,KAAK;AAElF,UAAM,SAAS,mCAAmC,cAAc;;EAElE,IAAI;AAEF,WAAO,KACL,KAAK,GAAG,OAAO,gBAAgB;MAC7B,OAAO;MACP,UAAU;KACX,CAAC,EACF,KACA,IAAI,cAAW;AACb,cAAQ,IAAI,yCAAqB,QAAQ;AAEzC,UAAI,YAAY,SAAS,MAAM;AAC7B,cAAM,iBAAiB,SAAS,KAAK,KAAI;AACzC,eAAO;UACL,cAAc;UACd;UACA,gBAAgB;UAChB,SAAS;;MAEb,OAAO;AACL,cAAM,IAAI,MAAM,+EAAmB;MACrC;IACF,CAAC,GACD,WAAW,WAAQ;AACjB,cAAQ,MAAM,yCAAqB,KAAK;AACxC,UAAI,eAAe;AACnB,UAAI,MAAM,SAAS;AACjB,uBAAe,MAAM;MACvB;AAEA,aAAO,WAAW,OAAO;QACvB,cAAc;QACd,gBAAgB;QAChB,gBAAgB;QAChB,SAAS;QACT,OAAO;QACP;IACJ,CAAC,CAAC;EAEN;;;;EAKA,uBAAuB,OAAiB,gBAAsB;AAC5D,UAAM,eAAoC,CAAA;AAE1C,WAAO,IAAI,WAAW,cAAW;AAC/B,UAAI,eAAe;AAEnB,YAAM,gBAAgB,MAAK;AACzB,YAAI,gBAAgB,MAAM,QAAQ;AAChC,mBAAS,KAAK,YAAY;AAC1B,mBAAS,SAAQ;AACjB;QACF;AAEA,cAAM,cAAc,MAAM,YAAY;AACtC,aAAK,cAAc,aAAa,cAAc,EAAE,UAAU;UACxD,MAAM,CAAC,WAAU;AACf,yBAAa,KAAK,MAAM;AACxB;AAEA,uBAAW,eAAe,GAAG;UAC/B;UACA,OAAO,CAAC,UAAS;AACf,yBAAa,KAAK;cAChB,cAAc;cACd,gBAAgB;cAChB;cACA,SAAS;cACT,OAAO,MAAM,WAAW;aACzB;AACD;AACA,uBAAW,eAAe,GAAG;UAC/B;SACD;MACH;AAEA,oBAAa;IACf,CAAC;EACH;;qCA1HW,2BAAwB;EAAA;4EAAxB,2BAAwB,SAAxB,0BAAwB,WAAA,YAFvB,OAAM,CAAA;;;sEAEP,0BAAwB,CAAA;UAHpC;WAAW;MACV,YAAY;KACb;;;;;ACsBK,IAAO,4BAAP,MAAO,2BAAyB;EAIhB;EAHH,kBAAkB;EAClB,eAAe;EAEhC,YAAoB,MAAgB;AAAhB,SAAA,OAAA;EAAmB;;;;EAKjC,0BAAuB;;AAE3B,aAAO;IAuBT;;;;;EAKA,cAAc,MAAc,gBAAsB;AAChD,QAAI,CAAC,KAAK,KAAI,GAAI;AAChB,aAAO,WAAW,MAAM,IAAI,MAAM,uEAAgB,CAAC;IACrD;AAEA,UAAM,cAAc;MAClB,WAAW;MACX,UAAU;MACV,YAAY;MACZ,WAAW;MACX,WAAW;MACX,UAAU;MACV,UAAU;;AAGZ,UAAM,iBAAiB,YAAY,cAA0C,KAAK;AAElF,UAAM,SAAS,yCAAW,cAAc;;;EAG1C,IAAI;;;AAIF,UAAM,cAAc;MAClB,OAAO,KAAK;MACZ;MACA,QAAQ;MACR,SAAS;QACP,aAAa;QACb,OAAO;QACP,YAAY;;;AAIhB,UAAM,UAAU,IAAI,YAAY;MAC9B,gBAAgB;KACjB;AAGD,WAAO,KAAK,KAAK,KAAqB,GAAG,KAAK,eAAe,iBAAiB,aAAa,EAAE,QAAO,CAAE,EACnG,KACC,IAAI,CAAC,aAA4B;AAE/B,UAAI,SAAS,YAAY,SAAS,SAAS,KAAI,GAAI;AACjD,eAAO;UACL,cAAc;UACd,gBAAgB,SAAS,SAAS,KAAI;UACtC;UACA,SAAS;;MAEb,OAAO;AACL,cAAM,IAAI,MAAM,uEAAgB;MAClC;IACF,CAAC,GACD,WAAW,CAAC,UAAS;AACnB,UAAI,eAAe;AAEnB,UAAI,MAAM,WAAW,GAAG;AACtB,uBAAe;MACjB,WAAW,MAAM,WAAW,KAAK;AAC/B,uBAAe,GAAG,KAAK,YAAY;MACrC,WAAW,MAAM,OAAO,OAAO;AAC7B,uBAAe,MAAM,MAAM;MAC7B,WAAW,MAAM,SAAS;AACxB,uBAAe,MAAM;MACvB;AAEA,aAAO,WAAW,OAAO;QACvB,cAAc;QACd,gBAAgB;QAChB;QACA,SAAS;QACT,OAAO;QACP;IACJ,CAAC,CAAC;EAER;;;;EAKA,cAAc,MAAc,cAAsB,WAAW,gBAAwB,UAAQ;AAC3F,QAAI,CAAC,KAAK,KAAI,GAAI;AAChB,aAAO,WAAW,MAAM,IAAI,MAAM,uEAAgB,CAAC;IACrD;AAEA,QAAI,SAAS;AAGb,YAAQ,aAAa;MACnB,KAAK;AACH,iBAAS;AACT;MACF,KAAK;AACH,iBAAS;AACT;MACF,KAAK;AACH,iBAAS;AACT;MACF;AACE,iBAAS;IACb;AAGA,YAAQ,eAAe;MACrB,KAAK;AACH,kBAAU;AACV;MACF,KAAK;AACH,kBAAU;AACV;MACF;AACE,kBAAU;IACd;AAEA,cAAU;;;EAAyD,IAAI;AAEvE,UAAM,cAAc;MAClB,OAAO,KAAK;MACZ;MACA,QAAQ;MACR,SAAS;QACP,aAAa;QACb,OAAO;QACP,YAAY;;;AAIhB,UAAM,UAAU,IAAI,YAAY;MAC9B,gBAAgB;KACjB;AAGD,WAAO,KAAK,KAAK,KAAqB,GAAG,KAAK,eAAe,iBAAiB,aAAa,EAAE,QAAO,CAAE,EACnG,KACC,IAAI,CAAC,aAA4B;AAE/B,UAAI,SAAS,YAAY,SAAS,SAAS,KAAI,GAAI;AACjD,eAAO;UACL,cAAc;UACd,gBAAgB,SAAS,SAAS,KAAI;UACtC,gBAAgB;UAChB,SAAS;;MAEb,OAAO;AACL,cAAM,IAAI,MAAM,uEAAgB;MAClC;IACF,CAAC,GACD,WAAW,CAAC,UAAS;AACnB,UAAI,eAAe;AAEnB,UAAI,MAAM,WAAW,GAAG;AACtB,uBAAe;MACjB,WAAW,MAAM,WAAW,KAAK;AAC/B,uBAAe,GAAG,KAAK,YAAY;MACrC,WAAW,MAAM,OAAO,OAAO;AAC7B,uBAAe,MAAM,MAAM;MAC7B,WAAW,MAAM,SAAS;AACxB,uBAAe,MAAM;MACvB;AAEA,aAAO,WAAW,OAAO;QACvB,cAAc;QACd,gBAAgB;QAChB,gBAAgB;QAChB,SAAS;QACT,OAAO;QACP;IACJ,CAAC,CAAC;EAER;EACM,qBAAkB;;AAEtB,aAAO,CAAA;IAQT;;;qCA7NW,4BAAyB,mBAAA,UAAA,CAAA;EAAA;4EAAzB,4BAAyB,SAAzB,2BAAyB,WAAA,YAFxB,OAAM,CAAA;;;sEAEP,2BAAyB,CAAA;UAHrC;WAAW;MACV,YAAY;KACb;;;",
  "names": []
}
